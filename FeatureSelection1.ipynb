{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96bcef08-7664-4cd4-a54c-a9066d3dc063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f96c59e-394e-4ba9-a2a0-c778e07068db",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffdb0511-1796-43d8-b7e2-47ade2e96642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECTKBEST FUNCTION\n",
    "def selectkbest(indep_x,dep_y,n):#Create a function selectkBest with 3 parameter\n",
    "      test = SelectKBest(score_func=f_regression, k=n)#select best feature using chi squared\n",
    "      fit1= test.fit(indep_x,dep_y)#create a model based on best feature\n",
    "      selectk_features = fit1.transform(indep_x)#Create a new indep_x dataset based on k values\n",
    "      return selectk_features   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73a23be7-240b-4d33-ae73-e8e76ce1322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARDIZATION FUNCTION\n",
    "def split_scalar(indep_x,dep_y):\n",
    "      X_train, X_test, y_train, y_test = train_test_split(indep_x, dep_y, test_size = 0.25, random_state = 0)#split training set and test set\n",
    "      sc = StandardScaler() # call standardization function\n",
    "      X_train = sc.fit_transform(X_train)#find mean and standard divation for x_train\n",
    "      X_test = sc.transform(X_test)    \n",
    "      return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4a7582a-97ea-4f54-96bb-6c43e4a24795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIND EVALUATION METRICS FOR REGRESSION\n",
    "def r2_prediction(regressor,X_test,y_test):#Create a function r2_prediction with 3 arguments\n",
    "     y_pred = regressor.predict(X_test)#findout the predicted output based on X_test(input)\n",
    "     r2=r2_score(y_test,y_pred)#Findout r2_score value \n",
    "     return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0722ff34-1084-4243-aa95-c25e48768211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGRESSION ALGORITHM\n",
    "def Linear(X_train,y_train,X_test):       \n",
    "        regressor = LinearRegression()#Call linearregression fun\n",
    "        regressor.fit(X_train, y_train)#Create a model\n",
    "        r2=r2_prediction(regressor,X_test,y_test)#call r2_prediction & findout r2 value \n",
    "        return  r2   \n",
    "\n",
    "def svm_linear(X_train,y_train,X_test):\n",
    "        regressor = SVR(kernel = 'linear')\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2  \n",
    "\n",
    "def svm_NL(X_train,y_train,X_test):   \n",
    "        regressor = SVR(kernel = 'rbf')\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2    \n",
    "    \n",
    "def Decision(X_train,y_train,X_test):\n",
    "        regressor = DecisionTreeRegressor(random_state = 0)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2 \n",
    "    \n",
    "def random(X_train,y_train,X_test):       \n",
    "        regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2 \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5593acb7-e2e2-4623-944d-22ab3390a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE A TABLE\n",
    "def selectk_regression(acclin,accsvml,accsvmnl,accdes,accrf): #Create a function  with 5 arguments\n",
    "    #Create a table,row named as Chisquare,column named as linear,SVMl,SVMnl,Decision,Random  \n",
    "    dataframe=pd.DataFrame(index=['f_regression'],columns=['Linear','SVMl','SVMnl','Decision','Random'])                                                                                     \n",
    "    for number,idex in enumerate(dataframe.index):#In the for loop  enumerate(dataframe.index) gives ChiSquare,number start from 0to 4\n",
    "        dataframe['Linear'][idex]=acclin[number] # #dataframe['Linear'][ChiSquare]=r2lin[0]    \n",
    "        dataframe['SVMl'][idex]=accsvml[number]#dataframe[SVMl'][ChiSquare]=r2svml[1]\n",
    "        dataframe['SVMnl'][idex]=accsvmnl[number]#dataframe['SVMnl'][ChiSquare]=r2svmnl[2]\n",
    "        dataframe['Decision'][idex]=accdes[number]#dataframe['Decision'][ChiSquare]=r2des[3]\n",
    "        dataframe['Random'][idex]=accrf[number]#dataframe['r2rf'][ChiSquare]=r2rf[4]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e731894e-7e38-4c39-a62e-29d0922c84b1",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "df2 = pd.read_csv(\"teen_phone_addiction_dataset.csv\", index_col=None)\n",
    "df2.drop(['Name', 'Location'], axis=1, inplace=True)\n",
    "df2= pd.get_dummies(df2,columns=['Gender','School_Grade','Phone_Usage_Purpose'],dtype=int,drop_first=True)\n",
    "#df2=pd.get_dummies(df2,dtype=int,drop_first=True)\n",
    "# Step : Define independent and target variables\n",
    "indep_x = df2.drop('Addiction_Level',axis=1)\n",
    "dep_y = df2['Addiction_Level']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d84e8176-3d21-42e9-8c45-6d5489991544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kbest=selectkbest(indep_x,dep_y,6) # call the fun & put k=5    \n",
    "\n",
    "acclin=[]#Create a empty list\n",
    "accsvml=[] \n",
    "accsvmnl=[]\n",
    "accdes=[]\n",
    "accrf=[]\n",
    "\n",
    "X_train, X_test, y_train, y_test=split_scalar(kbest,dep_y) #Kbest select best 5 feature,and split into training set and test set    \n",
    "r2_lin=Linear(X_train,y_train,X_test)\n",
    "acclin.append(r2_lin)\n",
    "    \n",
    "r2_sl=svm_linear(X_train,y_train,X_test)    \n",
    "accsvml.append(r2_sl)\n",
    "    \n",
    "r2_NL=svm_NL(X_train,y_train,X_test)\n",
    "accsvmnl.append(r2_NL)\n",
    "    \n",
    "r2_d=Decision(X_train,y_train,X_test)\n",
    "accdes.append(r2_d)\n",
    "    \n",
    "r2_r=random(X_train,y_train,X_test)\n",
    "accrf.append(r2_r)\n",
    "    \n",
    "    \n",
    "result=selectk_regression(acclin,accsvml,accsvmnl,accdes,accrf)#call selectk_regression fun then only the output comes in table format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfa49df9-0a3a-470a-95bf-6ab1436b104f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f_regression</th>\n",
       "      <td>0.722553</td>\n",
       "      <td>0.712625</td>\n",
       "      <td>0.985651</td>\n",
       "      <td>0.690482</td>\n",
       "      <td>0.886317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Linear      SVMl     SVMnl  Decision    Random\n",
       "f_regression  0.722553  0.712625  0.985651  0.690482  0.886317"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453aa55d-99e0-481d-8950-e3ee897bb936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8657123-dd6e-4f67-8897-7704ecaead89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
